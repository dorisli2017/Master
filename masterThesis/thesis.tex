\documentclass[12pt,a4paper,twoside]{scrartcl}

% Loading babel to enable automatic hypentation and multiple languages in the document.
% The last language in the option list will be used as default.
\usepackage[ngerman,english]{babel}
% Using T1 font encoding and the Latin Modern font
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{lscape}
\usepackage{afterpage}

% Using utf8 as file encoding.
\usepackage[utf8]{inputenc}
\usepackage[capbesideposition=outside,capbesidesep=quad]{floatrow}


% Page size. Using almost the whole A4 paper.
\usepackage[tmargin=22mm,bmargin=22mm,lmargin=20mm,rmargin=20mm]{geometry}


% Some standard packages for writing papers
\usepackage{latexsym,amsmath,amssymb,mathtools,textcomp}

% Paragraphs are not indented but there will be some space between paragraphs
\usepackage{parskip}
% For defining theorem-style environments like Lemma/Proof/Definition
\usepackage{amsthm}
% Fixing spacing problems before theorems due to \usepackage{parskip}
\begingroup
    \makeatletter
    \@for\theoremstyle:=definition,remark,plain\do{%
        \expandafter\g@addto@macro\csname th@\theoremstyle\endcsname{%
            \addtolength\thm@preskip\parskip
            }%
        }
\endgroup

% Some theorem-style environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
% Setting equation numbers to <chapter>.<section>.<index>
\numberwithin{equation}{section}

% For inserting graphics into the document
\usepackage{graphicx}
\graphicspath{{images/}}

% For tables
\usepackage{array,multirow}

% Control layout of itemize, enumerate, description
\usepackage{enumitem}

\setlist[enumerate]{topsep=0pt}
\setlist[itemize]{topsep=0pt}
\setlist[description]{font=\normalfont,topsep=0pt}

\setlist[enumerate,1]{label=(\roman*)}

% TikZ for graphics in LaTeX
\usepackage{tikz}
\usetikzlibrary{calc}

% Have the current section and subsection in the header.
\usepackage{fancyhdr}
\usepackage{ltxtable} 
\fancypagestyle{plain}{
  \setlength\footskip{32pt}
  \fancyhead{}
  \fancyfoot{}
  \fancyfoot[LE,RO]{\normalsize\thepage}
  \renewcommand{\headrulewidth}{0pt}
  \renewcommand{\footrulewidth}{0pt}
}

\fancypagestyle{normal}{
  \setlength{\headheight}{20pt}
  \setlength\footskip{32pt}
  \fancyhead{}
  \fancyhead[LE]{\normalsize\textsc{\nouppercase{\leftmark}}}
  \fancyhead[RO]{\normalsize\textsc{\nouppercase{\rightmark}}}
  \fancyfoot{}
  \fancyfoot[LE,RO]{\normalsize\thepage}
  \renewcommand{\headrulewidth}{0.4pt}
  \renewcommand{\footrulewidth}{0pt}
}

% Hyperref for hyperlinks und cross refs
\usepackage{color}
\usepackage{lscape}
\usepackage[pagebackref]{hyperref}
\usepackage[all]{hypcap}
\usepackage{pbox}
\DeclareOldFontCommand{\bf}{\normalfont\bfseries}{\mathbf}
\hypersetup{
  pdftitle={SAT Solving with distributed local search},
  pdfauthor={Guangping Li}, 
  pdfsubject={SAT solver, \emph{\textbf{SAT}},distributed local search}, 
  colorlinks=true,
  pdfborder={0 0 0},
  bookmarksopen=true,
  bookmarksopenlevel=1,
  bookmarksnumbered=true,
  linkcolor=black,
  %linkcolor=black,
  citecolor=black,
  urlcolor=black,
  filecolor=black,
  pdfpagemode=UseNone,
  unicode=true,
}

% Add the word "page" for pagebackref's in the bibliography.
\renewcommand*{\backreflastsep}{, }
\renewcommand*{\backreftwosep}{, }
\renewcommand*{\backref}[1]{}
\renewcommand*{\backrefalt}[4]{%
  \ifcase #1 %
No citations.% use \relax if you do not want the "No citations" message 
  \or
(Page #2).%
  \else
(Pages #2).%
  \fi%
}


% For importing graphics from subdirectories.
\usepackage{import}

% Referencing figures, etc.
\newcommand{\reflst}[1]{\hyperref[#1]{Listing~\ref*{#1}}}
\newcommand{\refthm}[1]{\hyperref[#1]{Theorem~\ref*{#1}}}
\newcommand{\refdef}[1]{\hyperref[#1]{Definition~\ref*{#1}}}




% Package for inserting pseudo codes in the document.
\usepackage[ruled,vlined,linesnumbered,norelsize]{algorithm2e}
\DontPrintSemicolon
\def\NlSty#1{\textnormal{\fontsize{8}{10}\selectfont{}#1}}
\SetKwSty{texttt}
\SetCommentSty{emph}
\def\listalgorithmcfname{List of Algorithms}
\def\algorithmautorefname{Algorithm}
\let\chapter=\section % resolve a problem with algorithm2e

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{empty} % no page number
\pagenumbering{alph}

% title page
\begin{titlepage}

  \begin{center}\large

    {\flushleft\includegraphics[height=17mm]{kit_logo_en.pdf} \hfill}
%    \includegraphics[height=20mm]{grouplogo-algo-blue.pdf}\quad\null

    \vfill

    \vspace*{2cm}

    {\bf\huge SAT Solving  \\ with distributed local search \par} 
    % Be sure to fill in the field pdftitle={} above
    % mit \par am Ende stimmt der Zeilenabstand
  

    \vfill
Master Thesis of \\

    \vspace*{15mm}
    {\bf Guangping Li} 

    \vspace*{15mm}

    At the Department of Informatics\\
Institute of Theoretical informatics, Algorithmics II 

    \vspace*{45mm}

    \begin{tabular}{rl}
      Advisors: & Dr. Tom{\' a}{\v s} Balyo \\
      & Prof. Dr. Peter Sanders  \\
    \end{tabular}
    
    \vspace*{10mm}

	% Deutsch
%    Institut für Theoretische Informatik, Algorithmik \\
%    Fakultät für Informatik \\
%    Karlsruher Institut für Technologie

    % English:
%     Institute of Theoretical Informatics, Algorithmics \\

    \vspace*{12mm}
  \end{center}
\afterpage{\null\newpage}
\end{titlepage}
\afterpage{\null\newpage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{0pt}\vfill

\selectlanguage{ngerman}
\hrule\medskip

Hiermit versichere ich, dass ich diese Arbeit selbständig verfasst und keine anderen, als die angegebenen Quellen und Hilfsmittel benutzt, die wörtlich oder inhaltlich übernommenen Stellen als solche kenntlich gemacht und die Satzung des Karlsruher Instituts für Technologie zur Sicherung guter wissenschaftlicher Praxis in der jeweils gültigen Fassung beachtet habe.

\bigskip

\noindent
Karlsruhe, 20th September 2018 

% Hand-written signature!! %TODO

\vspace*{5cm}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace*{0pt}\vfill
\selectlanguage{english}
\begin{abstract}
\centerline{\bf Abstract}
{\noindent Stochastic local search (SLS) is an elementary technique for solving combinational problems. Probsat is an algorithm paradigm of the simplest SLS solvers for Boolean Satisfiability Problem (SAT), in which the decisions only based on the probability distribution. In the first section of this paper, we introduce an efficient Probsat heuristic. We experimentally evaluate and analyze the performance
of our solver in a combination of different techniques, including simulated annealing and WalkSAT. With the approach of formula partition, we introduce a parallel version of our solver in the second section. The parallelism improves the Efficiency of the solver. Using different random generator and other parameter settings in solving
the sub-formula can bring further improvement in performance to our parallel solver.}
\end{abstract}
\vfill
\afterpage{\null\newpage}
\selectlanguage{ngerman}
\begin{abstract}
\centerline{\bf Zusammenfassung}
{\noindent Stochastische lokale Suche (SLS) stellt eine elementare Technik zur Lösung von komplizierten kombinatorischen Problemen dar. Probsat ist einer der einfachsten SLS-Solver für das Erfüllbarkeitsproblem der Aussagenlogik (SAT), bei dem die Entscheidungen nur auf der Wahrscheinlichkeitsverteilung basieren. Im ersten Teil dieser Arbeit stellen wir eine effiziente Probsat-basierte Heuristik vor. Die Leistung unseres Algorithmus in einer Kombination verschiedener Techniken, einschließlich simulierter Abkühlung und WalkSAT wurde auch experimentell bewertet und analysiert. Mit dem Ansatz der Formelpartition wird im zweiten Teil eine parallele Version unseres Algorithmus eingeführt, die die Effizienz des Lösers verbessert. Die flexible Parametereinstellungen bei der Lösung der Teil-formeln kann eine weitere Verbesserung unseres Algorithmus bringen.
 }
\end{abstract}


\vfill\vfill\vfill
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\selectlanguage{english}
\pagestyle{plain}
\pagenumbering{roman}
  
% markiere sections im Seitenkopf links und subsections rechts
\renewcommand\sectionmark[1]{\markboth{\thesection\quad\MakeUppercase{#1}}{\thesection\quad\MakeUppercase{#1}}}
\renewcommand\subsectionmark[1]{\markright{\thesubsection\quad\MakeUppercase{#1}}}


\tableofcontents
\afterpage{\null\newpage}
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{normal}
\pagenumbering{arabic}

\section{Introduction} 
\label{sec:Intro}
\subsection{Problem/Motivation} 
The \emph{\textbf{propositional satisfiability problem}} (\emph{\textbf{SAT}}) is the first proven NP-complete problem \cite{cook1971complexity}. The problem is to determine whether an assignment of Boolean values to variables in a  Boolean formula such that the expression evaluates to true. Hard combinational problems can be resolved with appropriate Encoding as a sat problem.
The SAT problem has many applications in computer science like chip model checking  \cite{clarke2001bounded}, software verification \cite{ivanvcic2008efficient} or in automated planning and scheduling in artificial intelligence  \cite{kautz1999unifying}. 
Formula partition is one of the promising approaches in DPLL-like solvers  \cite{mann2017guiding}. By giving the order to the variables according to a good formula partition, the search gets a relatively balanced decision tree. But formula partition is rarely used in a local search for the SAT problem. How to combine the formula partition with local search, will the local search benefit from the partitioning, if the formula partitioning can guide a parallel local search, are still open questions. 

\subsection{Content} 
The SAT problem, as a well-known NP-complete problem, has received a great deal of attention and different local search heuristics have been developed. This paper is a survey on the stochastic local search on SAT problem with a guide of formula partition. \\
In section ~\ref{sec:Intro}, we summarize the formal concept and introduces techniques used in this paper. 
One class of the most straightforward but efficient stochastic local search algorithms Probsat is the algorithm basic in our paper. Probsat was proposed in 2012 by Adrian Balint and Uwe Schoening \cite{balint2016engineering}. Section ~\ref{sec:local} describes our Probsat algorithm and discusses our attempts to improve the original algorithm. By experimentally evaluation and comparison, some techniques turned out to be more efficient than the simple Probsat search. With the partition of variables and its corresponding formulas, the problem can be separated into two subproblems of similar size.  In section ~\ref{sec:parallel}, we search the potential benefit of formula partition in a parallel search. Section ~\ref{sec:eva} describes the details in experiments and several empiric results mentioned in section 2 and section 3.  Section ~\ref{sec:conc} concludes the paper with further works. 

\subsection{Definitions and Notations} 
\emph{\textbf{Propositional Satisfiability Problem}}\\
A variable with two possible logical values  \textit{TRUE} or  \textit{False} is a \emph{\textbf{propositional variable}}, which will be referred to as \emph{\textbf{variable}} in this paper.
A \emph{\textbf{literal}} is an atomic formula in propositional logic. A literal can either be a \emph{\textbf{positive literal}} $v$ as the variable $v$ or a \emph{\textbf{negative literal}} $\bar{v}$ as negation of $v$.
A \emph{\textbf{clause}} is a disjunction of literals. A formula in conjunctive normal form (CNF) is a conjunction of clauses. We refer it as  \emph{\textbf{CNF-formula}} or simply as \emph{\textbf{formula}} in this paper.
An \emph{\textbf{assignment}} a as a function  $a$: $V\rightarrow \{True {, }\; False\}$ assigns the truth value to each variable $v$ in the formula. We say the assignment satisfies a formula if the truth value of the formula with this assignment turns out to be true. Specifically, an assignment satisfies a clause, if one literal in the clause with value  \textit{True} in this assignment. A formula is a satisfying formula if one assignment exists satisfies all its clauses. We say an assignment a satisfying assignment if it satisfies the formula. Otherwise, we say there are conflicts in some clauses with this assignment, or some clauses are unsatisfying clauses with this assignment. 
The SAT problem is to determine whether a satisfying assignment exists for the given formula. If so, we denote the formula a \emph{\textbf{satisfiable formula}}. \\
\\
Here is an example of SAT problem:
\begin{center}
\begin{table}
\begin{tabular}{l}
$F = (v_1 \lor \bar{v_3}) \land (v_2 \lor v_1 \lor \bar{v_1})$\\	
$Vars(F) = \{v_1, v_2, v_3\}$\\
$numVs(F) = |Vars(F)| = 3$\\
$Lits(F) = \{v_1, \bar{v_1}, v_2, v_3, \bar{v_3}\}$\\
$Cls(F) = \{C_1, C_2\}$\\
$numCs(F) = |Cls| = 2$\\ 
$C_1 = \{v_1, \bar{v_3}\}$\\
$C_2 = \{v_2, v_3, \bar{v_1}\}$\\
\\
$A(v_1)$ = $True$, $A(v_2)$ = $False$, $A(v_3)$ = $True$, \\
$A$  is an assignment satisfies $F$.\\
\\
$\hat{A}(v_1)$ = $True$, $\hat{A}(v_2)$ = $False$, $\hat{A}(v_3)$ = $False$, \\
$\hat{A}$  is an assignment with conflict in $C_2$.\\
\\
\end{tabular}
\label{table:kysymys}
\end{table}
\end{center}




\emph{\textbf{Set}}\\
A set is a container of unique elements. A set of 3 objects a, b, c is written as {a, b, c}. The
size of a set is the number of elements in the set.


\emph{\textbf{Local Search}}\\
For instance $I$ of a hard combinational Problem $P$, there is a set of solutions $S$.  According to the constraints of the problem, an object function (score or cost) $\Gamma$ is used to evaluate the candidate solutions. The Goal of the local search is to find the solution of minimum cost ( or the solution with the maximal score).\\
A local search starts with an initial complete solution. According to some heuristic, the local search makes local changes to its current solution iteratively, hence the name \emph{\textbf{local search}}. Starts from an initial solution, the search will evaluate the solutions which can be reached by applying a local change to the current solution and choose one of the neighbor solutions with local optimization. The search applies local moves until the optimal solution is reached, or in some cases, a generally good solution is reached.  Local search is widely used in hard combinational problems such as the traveling salesman problem [13] and the graph coloring problem [14]. \\
\\
\emph{\textbf{Local Search in SAT Problem}}\\
In the Boolean satisfiability problem, a local search operates primarily as follows: The search start from a randomly generated assignment as the initial solution. If this current assignment satisfied the formula, the search stops with success. Otherwise, a variable is chosen depends on some criterion. This selection is called \emph{\textbf{pickVar}}. By change the assignment of the selected variable $v$, a neighbor assignment of our current solution $A$ is reached in next step, which is also called  \emph{\textbf{flipp$(A,v)$}}. A local search will move in the space of the assignments by making the variable flipping until a satisfying assignment is reached by the search. \\
The heuristic used for the flipping variable selection $pickVar$  is based on some scores of the variables in the current assignment. Consider the assignment $\hat{A}$  reached by taking a flip of the variable in the current assignment $A$. The number of clauses satisfied in $A$,but not in $\hat{A}$ is called the \emph{\textbf{breakcout}} of the local move from $A$ to $\hat{A}$. Accordingly, the number of clauses, which become satisfying because of the flipping, is the  \emph{\textbf{makecount}}. The number of newly satisfying clauses ($makecount$) minus the number of newly unsatisfying clauses ($breakcount$), which is denoted as \emph{\textbf{diffscore}}, represents the local improvement of the corresponding flipping. Apart from this, other aspects like the repetition number of one flip or the number of occurrences of the variables can be considered in a selection heuristic. An example is the unit propagation embedded local solver $EagleUp$, which prefers flipping of variables with the highest number of occurrences in a formula to creates new unit clauses sooner. To get local improvement effectively, man can only consider variables in unsat clauses for the flipping selection. This process is called a \emph{\textbf{focused local search}} and commonly used. \\
\begin{algorithm}[H]
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwInOut{Parameter}{parameter}
 \Input{A CNF Formula F}
 \Parameter{$Timeout$}
 \Output{a satisfying assignment $A$}
  $A \leftarrow$ random generated assignment  $A$;\;
 \While {$( \exists$ unsatisfied clause $ \land$ Timeout does not occur$)$}{
  $c \leftarrow$ random selected  unsatisfied clause ;\;
  $x \leftarrow pickVar(A,c)$\;
  $A \leftarrow flip(A,x)$;\;
 }
 \caption{Focused Local Search}
\end{algorithm}  

By choosing the variable with best score in $pickVal$, the seach will get greedy local improvemnet. 
The initial hope of the local search is that through iterative greedy local improvement the optimal global solution can be found. The typical problem of the local search is that the greedy local searches be trapped in local unattractive local optimal solution.  To avoid this , some random flips are picked or even a worse solution  will be chosen for the next step (\emph{\textbf{uphill moves}}). There are some techniques following used in local search to avoid getting stuck in local optimum.

\emph{\textbf{Stochastic Local Search (SLS)}}\\
The stochastic local search will use the probability distribution of the scores of candidate solutions instead of the static decision. For the candidate moves, the probability of being chosen $p(\Gamma(s))$ corresponds to the score $\Gamma(s)$ of the solution $s$. In this way, the advantage a move is, the probability of choosing it as the next step is higher. This randomization will avoid the stuck of the search in a local minimum and decrease the misguiding of the heuristic in specific situations. \\
\\
\emph{\textbf{Statistical Local Search }}\\
 Tabu search is created by Fred W. Glover in 1986 [15] and formalized in 1989.  For recognize the loop in a suboptimal region, the search trace is recorded in the process by mark the recently reached neighboring assignments as tabu. The tabu moves will not be touched in the further search to discourage getting stuck in a region. \\
\\
\emph{\textbf{Simulated Annealing}}\\
Simulated Annealing is an approach of local search solver to difficult combinational optimization problems proposed by Kirkpatrick, Gelatt, and Vecchi \cite{kirkpatrick1983optimization}. This approach is inspired by the metallic process annealing of shaping the material by heating and then slowly cooling the material. This approach works as a local optimization algorithm guided by a controlling parameter \emph{\textbf{temperature}}. By high temperature, an uphill move is allowed with high probability while only small steps are allowed in low temperature. The temperature is varying according to the score of the current situation.  For a current solution with a nearly optimal score, the temperature is near zero. For an unattractive local extreme with a poor score, the active search is tending to make uphill moves in high temperature.\\
\\
\emph{\textbf{WalkSAT}}\\
WalkSAT is a focused random local search strategy to solve SAT problem, which is originally introduces in 1994 \cite{hoos2002adaptive}\\. WALKsat may ignore the greedy flipping and flip a random variable in chosen unsatisfied clause wit probability $p$ . By introducing these "uphill noises", the WalkSAT combines greedy local search and random walk to get an effective and robust random solver. \\
\\
\begin{algorithm}[H]
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwInOut{Parameter}{parameter}
 \Input{current assignment $A$, unsatisfied clause $c$}
 \Parameter{probability $p$}
 \Output{a variable $x$ in $c$ for flipping}
\For{$v$ in $c$}{
  Evaluate $v$ with function $\Gamma(A,v)$;\;
 }
  with probability $p$: $x \leftarrow$   $v$ with maximum $\Gamma(A,v)$; \;
  with probability $1-p$:  $x \leftarrow$  randomly selected $v$ in $c$. 
 \caption{pickVar in WalkSAT}
\end{algorithm}  

\emph{\textbf{The Probsat}}\\
Probsat is a class of SLS sat solver, which was introduced in 2012 by Adrian Balint and Uwe Schoening \cite{balint2016engineering}. In a probsat solver, the score of a candidate flip is solely based on the make and break score. The paradigm is as follows: At first, a completely random assignment is set as the initial assignment. The algorithm performs local moves by flip a variable in a random chosen unsatisfying clause and stops as soon as there are no unsatisfied clauses exists, which means a satisfying assignment is found. The probability $p(v)$ of flipping the variable $v$ in the chosen clause proportina to the score of $v$, which is calculated in a function $/Gamma(v,A)$ based on break score of $v$ in the current assignment $A$ \footnote{As mentioned in the probsat paper, it turns out in experiments that the influence of make is rather weak in selection functions, so the one parameter functions depends on $breakScore$ can also lead to an efficient algorithm.} The idea behind this selection heuristic is to give the advantageous flipping relative high score, but the other flipping with small score has chance to be chosen.  There are two kinds of score functions are considered in the paper of Adrian Balint: \\
\\
$\Gamma(v,A) = (c_b)^{-break(v,A)}$ (break-only-exp-function) \\
$\Gamma(v,A)=(\epsilon +break(v,A)^{-c_b})$  (break-only-poly-function)\\ 
\\
The pseudo code of a typical Probsat is shown below:\\
\begin{algorithm}[H]
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwInOut{Parameter}{parameter}
 \Input{current assignment $A$, unsatisfied clause $c$}
 \Output{a variable $x$ in $c$ for flipping}
\For{$v$ in $c$}{
  Evaluate $v$ with function $\Gamma(A,v)$;\;
 }
  $x \leftarrow$ randomly selected  variable $v$ in $c$ with probability $p(v) =\frac{\Gamma(A,v)}{\sum_{u \in c}\Gamma(A,u)}$; 
 \caption{pickVar in probSAT}
\end{algorithm} 
\emph{\textbf{Formula partition}}\\
To introduce our parallel SAT solver with formula partitioning, we use a  hypergraph representation of SAT problem. \\
A hypergraph $G = (V,H)$ is a generalized graph, in which an hyperedge $h \in H$ is a non-empty subset of the vertices set $V$. For a SAT Formula $F$, its hypergraph representation $G(F)$ = ($Vars(F),Cls(F)$) consists of $numVs$ vertices and $numCs$ hyperedges. 
  Each vertex corresponds to a variable in $F$, and a hyperedge refers to a clause, which connects the variables in this clause. \\
\\
Here is an example:\\
$F =\underbrace{(v_1 \lor v_2 \lor \bar{v_3})}_\text{$C_1$} \land \underbrace{(v_1 \lor v_3\lor \bar{v_4})}_\text{$C_2$}\land \underbrace{(v_5 \lor v_6\lor \bar{v_8})}_\text{$C_3$}\land \underbrace{(v_6 \lor v_7\lor \bar{v_8})}_\text{$C_4$}\land \underbrace{(v_3v\lor \bar{v_6})}_\text{$C_5$}\land \underbrace{(v_4 \lor v_5)}_\text{$C_6$}$\\
$G(F)$:
\begin{figure}[H]
\begin{center}
  \includegraphics[scale = 0.4]{1/hypergraph.png}
  \end{center}
  \caption{In a hypergraph, a hyperedge is a set of vertices. In our example, the vertices  $v_3$  and $v_4$ are both in hyperedge $\{v_1, v_3, v_4\}$ and $\{v_1, v_2, v_3\}$, so they are connected twice. In our hypergraph representation of SAT problem, a hyperedge contains the vertices of the corresponding clauses. Another variant is a hypergraph representation, in which each literal refers to one vertex, and a hyperedge contains all the literals of the corresponding clause.}
  \label{hypergraph representation}
  \end{figure}

Formula partition is a promising way to improve the SAT problems solving. Two partitioning are investigated in some works. One is to split the variables, which is used in this paper, and another one is to separate the clauses. For the algorithms with the technique of decision tree like DPLL, the formula partition can guide the order of decisions. For the local search, there is nearly research of the use of formula partition in local search. Based on this hypergraph represenation, we describe in this paper the formula partition with the notations in graph partition. For a hypergraph $G = (V,H)$,  a ($2$-way) partitioning is to seperate the verices set in two disjoint subsets. A good partition is to seperate $V$ in $P_1$ and $P_2$, which are of relative same size and only few hyperedges containing both verticse in $P_1$ and vertices in $P_2$.  Based on a vertices partitioning, the hyperedges are seperated in three disjoint subsets $H_1$, $H_2$ and $I$. $H1$ contains the edeges connecting verticse in $P_1$, $H_2$ are edges in $P_2$. The \textbf{intersection} $I$ are the edges containing vertices in $P_1$ and vertices in $P_2$.In our example formula above, a minimum cost balanced partition is $P_1$ = $\{v_1,v_2, v_3, v_4\}$ and $P_2$ = $\{v_5,v_6, v_7, v_8\}$. In this partition, $H_1$ = $\{C_1,C_2\}$ , $H_2$ = $\{C_4,C_5\}$ and the intersection $I$ = $\{C_5,C_6\}$ 
\clearpage
\subsection{The Competitors}
\label{comparision}
Our heuristic is based on the probSAT paradigm. To evaluate the performance of our algorithm, we compare our heustic with the original ProbSAT. Another random SAT solver used for a comparison with our algorithm is yalSAT, which is the champion in random track category in SAT competition 2017 \cite{biere2014yet}.\\
\\
\emph{\textbf{probSAT}} \footnote{https://github.com/adrianopolus/probSAT}
\\
The authors of the original Paper implement the ProbSAT. We compare our Solver with this original code \footnote{Using same parameter settings our implementation gets similar performance to the original code}.  \\
In this original code, there are two implementation variants available. In the incremental approach, the breakScores of variables are calculated in the initialization phase and only updated in the further search. The other straightforward approach is to compute breakScores of the variables in consideration of flipping. This method is called non-incremental approach in original paper. As suggested in Experiments, we take the non-incremental approach for the 3SAT problems and incremental method for 5SAT and 7SAT to get optimal results of the probSAT solver.\\
The parameters of ProbSAT in our Experiments have been set as suggested in the original paper:\\
\begin{table}[h!]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{| l | l| l | l| l |p{3cm}|}
\hline 
    $k$SAT\footnote{k is the maximum length of the clause} & score $\Gamma$ & $c_b$ & $\epsilon$ &variants \\ \hline
    $3$SAT & break-only-poly& 2.06 & 0.9 &non-incrementel \\ \hline
    $5$SAT & break-only-exp & 3.7 & - & incremental \\ \hline
    $7$SAT &  break-only-exp & 5.4 & - & incremental \\ \hline
\end{tabular}
\caption[probSAT]{Parameter setting for competitor probSAT}
\end{center}
%\end{minipage}
\end{table} 

\emph{\textbf{yalSAT}} \footnote{https://baldur.iti.kit.edu/sat-competition-2017/solvers/random/}\\
We use the version 03 submitted to the 2017 SAT competition of the yalSAT solver in our experiments. Armin Biere implements it as a reimplementation with extensions of probSAT.  With the implementation of different variants of probSAT, the yalSAT uses a different variant of probSAT randomly in the restart of a round of search. In our comparison, we use the default settings of the yalSAT with specific seeds.
\clearpage
\section{Our local Solver}
\label{sec:local}
 Our algorithm is a typical focused SLS algorithm, which solves the SAT problem with the basic shema:\\
\\
\begin{algorithm}[H]
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwInOut{Parameter}{parameter}
 \Input{A CNF Formula F}
 \Parameter{$Timeout$}
 \Output{a satisfying assignment $A$}
  $A \leftarrow initAssign(F)$ \;
 \While {$( \exists$ unsatisfied clause $ \land$ Timeout does not occur$)$}{
  $c \leftarrow pickCla(A)$ ;\;
  $x \leftarrow pickVar(A,c)$\;
  $A \leftarrow flip(A,x)$;\;
 }
 \caption{Our Local Search}
\end{algorithm}
 In the following, we will describe the methods used in our local search.\\
\\
\subsection{initAssign(F)}
In our algorithm, we have three variants to make assignment initialization.
One is the $RandomInit$ which is the random initiation like in the original probsat suggests. Two alternatives to this random assignment are with the consideration of number of literal occurrences. with the method $BiasInit$ we assign $True$ to a variable if the number of occurrences of its positive literal is more than its negative literal. Otherwise, a variable is assigned initially with $False$. $Bias-RandomInit$ combines the two initializations above, in which the assignment is generated bias randomly based on the occurrences of literals.  In Experiment 1 in Section 4 (see ~\ref{sec:Experiment 1}) we compare these three alternatives based on the probsat algorithm. Our local search uses $RandomInit$ for 3SAT problems and $BiasInit$ for other problems.\\
\\
\subsection{pickCla(A)}
$numT(c)$ , the number of $True$ values in each clause $c$, are counted in Initilization phase and maintained in further search. The unsatisfying clauses will be cached in a set $UNSAT$. During the local flipping, these numbers will be updated when the flipping variable is in the clauses.  Comparing to the $numT$, the $UNSAT$ is updated lazily. After Flipping, if the $numT$ of one clause is decreased to zero, it will be added in the $UNSAT$.  To select an unsat clause in $pickCla(A)$, man needs to select a clause from the $UNSAT$ and Ocheck if it is still unsat with its $numT$ is zero. Otherwise, if the chosen clause $c$ with $numT(c)$ as zero, it will be removed from the $UNSAT$ set. This step pickCla(A) will be repeated until one unsatisfied clause is found or the $UNSAT$ set is empty, which means the current Assignment $A$ is a satisfying assignment.\\ 
\\
\subsection{pickVar(A,c)}
Inspired by probSAT and walkSAT, Our pickVar combines the random walk and stochastic selection. We analyze experimentally the following variants for  $pickVar$.\\
\\ 
 \emph{\textbf{1.Varinat:COMBINE}}\\
\\
In observation of the experiments of the probSAT, this stochastic search bases its selection on a random heuristic.  Even the search is very close to a satisfying assignment, and the probability of the critical flipping is exceptionally high, it is possible that the stochastic search make uphill moves and leave then the region of the global minimum. To prevent this besides the stochastic way,  we pick greedy flip with zero $breakScore$ with a certain probability $p$. With probability $1-p$, we choose the variable for flipping using the probSAT heristic.\\
\\
\begin{algorithm}[H]
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwInOut{Parameter}{parameter}
 \Input{current assignment $A$, unsatisfied clause $c$}
 \Parameter{probability $p$}
 \Output{a variable $x$ in $c$ for flipping}
 greedyVs $\leftarrow$ $\emptyset$;\;
\For{all $v$ in $c$}{
   \If{$($break(A,v)= 0 $\land$ $Permit(v))$}{
	greedyVs = greedVs +  $\{v\}$    
   }
 }
  with probability $p$: $x \leftarrow$ randomly selected variable $v \in$ greedyVs;  \;
  with probability $1-p$:   $x \leftarrow$ randomly selected  variable $v$ in $c$ with probability $\frac{\Gamma(A,v)}{\sum_{u \in c}\Gamma(A,u)}$;  
\caption{COMBINE}
\end{algorithm}  
 \emph{\textbf{2.Varinat: WALK}}\\
\\
Instead of using a constant probability $p$ to choose between a greedy Literal without clause break and the random Literal using probSAT flipping directly, we see a list, called statistic list $S$ to record how many times each variable is chosen for flipping.  To avoid cycling, we see the variable $v_i$ with a high value of S[i] to be disadvantages for flipping. After selecting a variable using the ProbSAT stochastic distribution, we make the choice randomly according to the statistic values of these two variables.\\
 \\
\begin{algorithm}[H]
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwInOut{Parameter}{parameter}
 \Input{current assignment $A$, unsatisfied clause $c$}
 \Parameter{probability $p$}
 \Output{a variable $x$ in $c$ for flipping}
 greedyVs $\leftarrow$ $\emptyset$;\;
\For{all $v$ in $c$}{
   \If{$($break(A,v)= 0 $\land$ $Permit(v))$}{
	greedyVs = greedVs +  $\{v\}$    
   }
 }
  $greedyV \leftarrow$   randomly selected variable $v \in$ greedyVs  ; \;
  $randomV \leftarrow$ randomly selected  variable $v$ in $c$ with probability $\frac{\Gamma(A,v)}{\sum_{u \in c}\Gamma(A,u)}$;  \;
  with probability $p = \alpha \times \frac{s(greedyV)}{s(greedyV)+s(randomV)}$: $x\leftarrow$ randomV;\;
    with probability $1-p$: $x\leftarrow$ greedyV;\;
\caption{WALK}
\end{algorithm} 
 \emph{\textbf{3.Varinat: GreedyBreak}}\\
\\  Compared to find the greedy Literals with zero breakScores, the calculation of the decay function $\Gamma$ values and get a random literal according to its distribution takes the most part in the whole search. In this variant $greedybreaking$, we search greedy Literal with small statistic value.  Hier, we define a literal is a permitted greedy Literal if its break value is zero and its statistic value is under some Limit. If permitted greedy variables exist, we choose one randomly for flipping. Otherweise, we pick random Literal using probSAT heuristic. To set the limit based on the search history, we compare two functions in our experiment. In the first approach "Average", the limit is set statistic to $\alpha*\frac{numFs}{numVs}$.\\
 In another approach "Random-Flip,"we select randomly a value $r $ in $[0, numFs]$. For each greedy Literal, we check if its statistic value is smaller than $\alpha * r$. \\
\begin{algorithm}[H]
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwInOut{Parameter}{parameter}
 \Input{current assignment $A$, unsatisfied clause $c$}
 \Parameter{probability $p$}
 \Output{a variable $x$ in $c$ for flipping}
  greedyVs $\leftarrow$ $\emptyset$;\;
\For{all $v$ in $c$}{
   \If{$($break(A,v)= 0 $\land$ $Permit(v))$}{
	greedyVs = greedVs + $\{v\}$   
   }
 }
  \If{$($greedyVs is not empty$)$}{
  		 x $\leftarrow$ selected variable $v$ in $greedyVs$ at random 
 	}
 \Else{
  x $\leftarrow$ randomly selected  variable $v$ in $c$ with probability $\frac{\Gamma(A,v)}{\sum_{u \in c}\Gamma(A,u)}$; }
  \;
\caption{TieBreak}
\end{algorithm} 
\subsection{pickVar(A,c) with Simulated Annealing}
Simulated Annealing is a technique, whose combination with WalkSAT is extensively studied. Besides the dynamic noises introduced above, we use simulated annealing to improve our three suggestions of $pickVal$.That is, we define the $\alpha$ as a function depending on the quality of current assignment $q$ instead of using a static parameter in the whole process.
To define the $temperature$, we have two variants: Global and Local.\\
\\
\textbf{Global}:\\
In the process of search, the number of unsatisfied clauses is shown in $unsatN$. In this traditional variant $Global$, we use this number to define the quality of the current solution.\\
\textbf{Local}:\\
As the name suggested, in the $Local$ variant, we measure the quality of the current assignment focused on the chosen clause/ The quality  $q(A,c)$ is equal to the number of greedy Literals in current clause.\\
\\
\begin{center}
 $q_{Global}(A) =unsatN(A)$.\\
 $q_{local}(A) =|{v| v in  c \land breaks(v) == 0}|$.\\
 $\alpha = (c_b)^{-q)}$\\
\end{center}


\label{sec:Simulated Annealing}
\subsection{Data structures}
\label{subsec:Data structures}
\emph{\textbf{ Occurrences}}
\\
In the process of initialization, the numbers of occurrences of one variable will be compared. In our implementation, we use a list to count and record these occurrences numbers. This list with size of $2*numClauses $ is denoted as Occurrences List OL. For the variable with index $i$, the $OL[2i]$ is the number of literal vs occurrences; The $OL[2i+1]$ is for its negative occurrences. \\
\\
\emph{\textbf{ Literals}}
\\
Local search is a search where only small changes are made in each step. In our Situation, only the clauses include the flipping variables are involved in the flipping step. The most time in our solver is spent to update the $numTs$ of these involving clauses. To find the involving clauses of one Variable,  two $2D$ Array $posL$ and $negL$is made to record the clauses of positive nad negative literals. For variable $v_i $, the posL[i] record the indexes of clauses containing the positive literal $v_i$. Tthe ones with negative literal $-v_i$ are in by $egL[i]$. To implement the flipping of the variable $v_i$, we update the $numTs$ of clauses with indexes in $posL[i]$ and $negL[i]$.\\
\\
\emph{\textbf{LookUp}}
\\
The most time used in the search is the repeated  calculation  of  tthe polynomial or exponential decay function $\Gamma$. With this observation in our experiments, we calculate the $\Gamma(x)$ with $x$ from $0$ to $0.5* numCs$ and keep the valuse in a list $LookUp$. In our implementation, we use this Table lookup to get the values instead of the reputation of time-consuming exponential operation.  \\
\\
\emph{\textbf{Solution}}
\\
A Solution in our implementation includes the boolean Assignment and three other structures to record information about the current assignment. The Solution is computed after assignment initialization and is updated during each flipping :\\
\begin{table}[h!]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|p{1cm}|}
\hline 
 	Name &Structure & Size & Meaning\\ \hline
    $Assignment$&list & numVs & boolean assignment to variables\\ \hline
	$NumTs$&list & numCs& number of $True$ values in each clause \\ \hline
	$NumUnsat$& natural number & -&the number of unsatisfied clauses  \\ \hline
	$UNSAT$& set & - & indexes of unsatisfied clauses \footnote{This UNSAT is updated in flipping phase lazily by only adding new unsatisfied clauses and remove the clause chosen in $pickCla$.}\\ \hline

	
\end{tabular}
\caption[probSAT]{Parameter setting for competitor probSAT}
\end{center}
%\end{minipage}
\end{table} 

\section{Our Parallel Algorithm}
\label{sec:parallel}
\label{sec:Our parallel Algorithm}
\subsection{1st Approach: The pure portfolio approach (no partition)}
\subsection{2nd Approach: Star}
\subsection{3nd Approach: Hope}
\subsection{4th Approach: future}

\clearpage
\section{Evaluation} 
\label{sec:eva}
 %TODO some server information
\subsection{DIMACS standard format}  
All the benchmark CNF formula used in experiments are encoded in the DIMACS standard format \cite{johnson1996cliques}. This format is used to test and compare SAT solver in SAT competition. A DIMACS file contains the description of an instance using three types of lines\footnote {Only clause unweighted simple instances are tested in our experiments. For other descriptors and details of the DIMACS format}:\\ \\ 1. Comment line: Comment lines give information about the graph for human readers, like the author of the file or the seed used in generation. A comment line starts with a lower-case character $c$ and will be ignored by programs:\\ \centerline{\textbf{c} \emph{ this is an example of the comment line }}\\ \\ 2. Problem line: The problem line appears exactly once in each DIMACS format file. The problem line is signified by a lower-case character $p$.  For a formula with $nV$ variables and $nC$ clauses ,the problem line in its DIMACS file is:\\ \centerline{\textbf{p} cnf $nV$ $nC$}\\ \\ 3. Clause Descriptor: An clause $\{v_1, v_2,, v_n\}$ in the graph is described in an edge Descriptor:\\ \centerline{\textbf{e} $v_1\; v_2\;  \;v_n$}\\  
\\
Here is the DIMACS format of the formula $F = (v_1 \lor \bar{v_3}) \land (v_2 \lor v_1 \lor \bar{v_1})$:
\begin{center}
\begin{tabular}{l}
c simple$\_v_3\_c_2$.cnf\\
p cnf 3 2\\
1 -3 0\\
2 3 -1 0 \\
\end{tabular}
\end{center}

\subsection{Benchmarks}
\label{benchmark}
The benchmark instances used in experiments are the 180 uniform instances (unif) in random benchmark categories in SAT competition 2017  \cite{balyo2017proceedings}. In an unif problem file, all the clause have the same length.
The suffix 'k'  denotes the length of clauses. The r indicates the clause-to-variable ratio. The c and v are for the number of clauses and variables, while s is for the seed used in the generation process.
 Without flitering, there are at least 60 ( $33\%$ ) problems form our 180 benchmark collections are unsatisfiable.
\subsection{Used plots and tables}
the results of the following experiments are all shown in comparision table and  illusatrated in cactus plot.  \\
\\
\emph{\textbf{Comparison Table}}\\
See Table \ref{tab:com} for example.\\
A comparison table shows the different results of algorithms. The first column contains the
clause length $k$. The UNIF benchmark has $3$ different sizes: $3$SAT, $5$SAT, and $7$SAT. For a $k$SAT instance, each clause contains k variables.  The fields of a comparison table in the following columns corresponds to a penalized runtime for the whole $k$SAT set, which assigns a runtime of two times the time limit for an unsolved instance. Because the UNIF benchmark graphs without filtering contain a part of unsatisfied problems, we assign penalized time only to problems which can not be solved by any solvers in our whole experiment. There are 61 $3$SAT instances, 89 $5$SAT instances and 66 $7$SAT instances found satisfied in our experiments. Besides the runtime score, the number of solved problems are in parentheses. The best results in comparison are in bold.
\\
\\
\emph{\textbf{Cactus Plot}}\\
See Figure \ref{Experiment 1 cactus plot} for an example.\\
A cactus plot shows the performance of different algorithms. The y-axis shows the time in second used to solve the benchmark graphs.  The y-axis is for the number of solved problems by a certain time. Each algorithm corresponds to a curve in different colors. The point $(u, v)$ on a curve means by $v$ seconds the corresponding algorithm have solved  $u$ problems.  \\

\subsection{Random seeds used in Experiments}
To make our experiments results reproducible and robust, we repeat our tests with three specific seeds. We produce the seeds in experiments as follows: First, we use the sum of characters of the name of the solver to seed the pseudo-random generator in c++.  Then we use this reinitialized generator to produce three random values, which are the seeds used later in our experiments. 
\begin{table}[h!]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|l|p{1cm}|}
\hline 
    solver&name&1.seed&2.seed&3.seed \\ \hline
	probSAT&probsat&1988822874&338954226 &858910419 \\ \hline
	yalSAT &yalsat&1851831967&280788293&1956345180 \\ \hline
	our local solver & local&1962042455&1112841915&566263966 \\ \hline
	our parallel solver & parallel &1749729997& 68910537& 473644167 \\ \hline
	
\end{tabular}
\caption[probSAT]{Parameter setting for competitor probSAT}
\end{center}
%\end{minipage}
\end{table} 
\subsubsection{Soft- and Hardware}
The single-threaded experiments were run on computers that had Two Intel Xeon E5-2683 v4 processors  (2.1 GHz 2x16-core + 2x16-HTcore) and 512GB RAM. The machine ran the 64-bit version
of  Ubuntu 14.04.5 LTS. 
\subsection{Parameter Settings in Experiment}
The $TimeOut$ is set to 5Minutes in the experiments of local searches.  For the probSAT heuristic, our local search uses the values for $c_b$ and $/epsilon$ suggested in the probSAT paper.  The $tolerence$ $ \tau$ used in the experiments is generated with the help of the algorithm parameter optimization tool SMAC [29] (sequential model-based algorithm configuration). SMAC ran our algorithms on LARGE problems in the UNIF category in SAT 2012 ($75\%$ of the instances training instances,  $25\%$ as test instances) using different   $ \tau \in [0, 10]$\footnote{Because of high time consume in parameter optimation, we solely compare $\tau$  as a natural number form One to Ten.}  and randomly generated seeds. With the help of SMAC.
   \begin{table}[H]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l||l|l|l|l|p{1cm}|}
\hline 

    k &$WALK$&$WALK_Local$&$WALK_Global$&$Average$&$Average_Local$&$Average_Global$ \\ \hline
    3 & 1& 1 & 10 &  1 & 2& 0.5       \\ \hline  
    5 & 0.5& 1 & 1&  1 & 2& 2 \\ \hline  
    7 & 1& 0.5 & 2&  1 & 2& 0.5  \\ \hline  
 \hline  
    k &$RF$&$RF_Local$&$RF_Global$&$swpSAT$&$\alpha$&$SA$ \\ \hline  
    3 & 1& 0.5 & 0.5&$Average$ & 1 & $-$\\ \hline 
    5 & 0.5& 2& 9.5&$Average$& 2 & $Local$\\ \hline 
    7 & 0.5& 1& 0.5 &$Average$&2 & $Local$\\ \hline 

	
\end{tabular}
\end{center}
%\end{minipage}
\end{table}
\subsection{Benchmark Generation}
To combine the hypergraph partitioning and SAT local solver, we try to get a relatively balanced graph partition with small intersection for the benchmark SAT problems.  On UNIF benchmark, we try to get graph partitioning using some partitioning algorithms (KaHypar and hmetis). Since the uniform random generation of this benchmark, these problems are without a real-world-like structure. Even with a high imbalance like 0.3 and high tolerance of intersection size ($50\%$ of edge sizes), the partitioning algorithms take more time than our SAT solver for more than $50\%$ of our UNIF benchmarks.  To investigate the local search on graphs with proper partitioning, we generate our benchmark COMBINE  using the UNIF benchmark instances.  As the name COMBINE suggested, we combine two UNIF benchmark instances in one SAT problem and make for the new generated problem with two disjoint subproblems an intersection.  To create a satisfiable formula, we build the intersection based on a pair of random chosen satisfying assignments of the two UNIF problems in combination. To get satisfying assignments of UNIF benchmarks, we run different solvers in SAT competitions including CSCCSat, DCCASat, score2SAT, probSAT, and yalSAT. We do not use our local search to collect satisfying assignments. Otherwise, it is possible that after solve the two partitioning sets individually using our local solver, the current assignment is the same or a similar one used for the intersection generation.\\
We combine the UNIF problems in consideration of real-world uses. 
We combine 4  pairs of instances in  $3$SAT, $5$SAT problems $7$SAT problems. Besides that, we consider five combinations between  3SAT and 5 SAT instances and three combination of $5$SAT and $7$SAT instances. 
We combine problem in similar vertices size, which corresponds to balanced partitioning in the structure. We also combine one massive problem with a small instance of an imbalanced partitioning. For the intersection generation part, we generate clauses with three vertices in different partitioning sets. \\
We first choose vertices of two partition sets for intersection generation randomly. Here we consider also the balanced intersection and imbalanced intersection. In a balanced intersection, same proportion of vertices in both partitioning sets are chosen to generate the intersection. In an imbalanced intersection, the portions are not the same.  To control the size of the intersection, we also count the number of the clauses in an intersection, if the proposition of the intersection clauses in the clauses number in whole combined problems is upper a specified limit, the generation of intersection is stopped.
\begin{table}[H]
\label{tab:combine big} 
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|p{1cm}|}
\hline 
Problem &Intersection \\ \hline
k3-r3.94.cnf-k3-r4.04.cnf-0.1-0.1-0.1.cnfP&	1.04\%\\  \hline
k3-r3.96.cnf-k3-r4.06.cnf-0.1-0.1-0.2.cnfP&	1.00\%\\  \hline
k3-r3.98.cnf-k3-r4.0.cnf-0.1-0.1-0.4.cnfP&	1.03\%\\  \hline
k7-r55.0.cnf-k7-r56.0.cnf-0.1-0.2-0.2.cnfP&	15.53\%\\  \hline
k7-r55.0.cnf-k7-r56.0.cnf-0.1-0.4-0.1.cnfP&	6.84\%\\  \hline
k7-r55.0.cnf-k7-r56.0.cnf-0.2-0.2-0.2.cnfP&	12.04\%\\  \hline
k7-r55.0.cnf-k7-r56.0.cnf-0.2-0.4-0.1.cnfP&	7.53\%\\  \hline
k7-r55.0.cnf-k7-r56.0.cnf-0.4-0.1-0.4.cnfP&	6.38\%\\  \hline
k7-r55.0.cnf-k7-r56.0.cnf-0.4-0.2-0.1.cnfP&	7.35\%\\  \hline
k7-r55.0.cnf-k7-r56.0.cnf-0.4-0.4-0.2.cnfP&	6.11\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.1-0.1-0.2.cnfP&	16.67\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.1-0.1-0.4.cnfP&	25.21\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.1-0.2-0.2.cnfP&	14.77\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.1-0.4-0.1.cnfP&	6.46\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.2-0.1-0.2.cnfP&	13.92\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.2-0.2-0.4.cnfP&	11.40\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.2-0.4-0.2.cnfP&	7.08\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.4-0.1-0.4.cnfP&	5.88\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.4-0.2-0.4.cnfP&	6.86\%\\  \hline
k7-r57.0.cnf-k7-r60.0.cnf-0.4-0.4-0.4.cnfP&	5.81\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.1-0.1-0.1.cnfP&	9.09\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.1-0.1-0.2.cnfP&	16.67\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.1-0.1-0.4.cnfP&	25.07\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.1-0.2-0.1.cnfP&	9.09\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.1-0.2-0.4.cnfP&	14.68\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.1-0.4-0.4.cnfP&	6.36\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.2-0.1-0.1.cnfP&	9.09\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.2-0.1-0.2.cnfP&	13.96\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.2-0.2-0.2.cnfP&	11.58\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.2-0.4-0.2.cnfP&	6.97\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.4-0.1-0.4.cnfP&	5.98\%\\  \hline
k7-r58.0.cnf-k7-r62.0.cnf-0.4-0.4-0.4.cnfP&	5.60\%\\  \hline
k7-r59.0.cnf-k7-r87.79-v90.cnf-0.1-0.1-0.4.cnfP&	1.30\%\\  \hline
k7-r59.0.cnf-k7-r87.79-v90.cnf-0.1-0.2-0.2.cnfP&	2.52\%\\  \hline
k7-r59.0.cnf-k7-r87.79-v90.cnf-0.1-0.4-0.2.cnfP&	4.88\%\\  \hline
\end{tabular}
\end{center}
%\end{minipage}
\end{table} 

\begin{table}[H]
\label{tab:combine small} 
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|p{1cm}|}
\hline 
Problem &Intersection \\ \hline
k3-r3.92.cnf-k3-r3.88.cnf-0.2-0.1-0.4.cnfP&	0.38\%	\\   \hline
 k3-r3.92.cnf-k3-r3.88.cnf-0.2-0.4-0.1.cnfP&	0.13\%	\\   \hline
 k3-r3.94.cnf-k3-r4.04.cnf-0.1-0.2-0.1.cnfP&	0.36\%	\\   \hline
 k3-r3.94.cnf-k3-r4.04.cnf-0.1-0.4-0.4.cnfP&	0.11\%	\\   \hline
 k3-r3.94.cnf-k3-r4.04.cnf-0.2-0.1-0.2.cnfP&	0.37\%	\\   \hline
 k3-r3.94.cnf-k3-r4.04.cnf-0.2-0.2-0.1.cnfP&	0.27\%	\\   \hline
 k3-r3.94.cnf-k3-r4.04.cnf-0.4-0.2-0.4.cnfP&	0.11\%	\\   \hline
 k3-r3.94.cnf-k3-r4.04.cnf-0.4-0.4-0.4.cnfP&	0.09\%	\\   \hline
 k3-r3.96.cnf-k3-r4.06.cnf-0.1-0.2-0.2.cnfP&	0.37\%	\\   \hline
 k3-r3.96.cnf-k3-r4.06.cnf-0.1-0.4-0.1.cnfP&	0.11\%	\\   \hline
 k3-r3.96.cnf-k3-r4.06.cnf-0.2-0.1-0.2.cnfP&	0.35\%	\\   \hline
 k3-r3.96.cnf-k3-r4.06.cnf-0.2-0.2-0.2.cnfP&	0.27\%	\\   \hline
 k3-r3.96.cnf-k3-r4.06.cnf-0.2-0.4-0.2.cnfP&	0.13\%	\\   \hline
 k3-r3.96.cnf-k3-r4.06.cnf-0.4-0.1-0.2.cnfP&	0.10\%	\\   \hline
 k3-r3.96.cnf-k3-r4.06.cnf-0.8-0.8-0.05.cnfP&	0.06\%	\\   \hline
 k3-r3.98.cnf-k3-r4.0.cnf-0.1-0.2-0.1.cnfP&	0.38\%	\\   \hline
 k3-r4.267-v11000.cnf-k5-r16.2.cnf-0.8-0.8-0.05.cnfP&	0.52\%	\\   \hline
 k3-r4.267-v11200.cnf-k5-r16.8.cnf-0.8-0.8-0.05.cnfP&	0.49\%	\\   \hline
 k3-r4.267-v11600.cnf-k5-r17.0.cnf-0.8-0.8-0.05.cnfP&	0.52\%	\\   \hline
 k3-r4.267-v7400.cnf-k5-r17.2.cnf-0.8-0.8-0.05.cnfP&	0.34\%	\\   \hline
 k3-r4.267-v9600.cnf-k5-r17.4.cnf-0.8-0.8-0.05.cnfP&	0.42\%	\\   \hline
 k5-r21.117-v200.cnf-k5-r16.0.cnf-0.1-0.1-0.2.cnfP&	0.04\%	\\   \hline
 k5-r21.117-v200.cnf-k5-r16.0.cnf-0.2-0.1-0.2.cnfP&	0.09\%	\\   \hline
 k5-r21.117-v200.cnf-k5-r16.0.cnf-0.4-0.1-0.4.cnfP&	0.17\%	\\   \hline
 k5-r21.117-v220.cnf-k5-r17.6.cnf-0.8-0.8-0.05.cnfP&	0.01\%	\\   \hline
 k5-r21.117-v280.cnf-k5-r16.4.cnf-0.1-0.1-0.4.cnfP&	0.06\%	\\   \hline
 k5-r21.117-v280.cnf-k5-r16.4.cnf-0.2-0.1-0.1.cnfP&	0.12\%	\\   \hline
 k5-r21.117-v280.cnf-k5-r16.4.cnf-0.4-0.1-0.1.cnfP&	0.23\%	\\   \hline
 k5-r21.117-v290.cnf-k5-r16.6.cnf-0.1-0.1-0.2.cnfP&	0.06\%	\\   \hline
 k5-r21.117-v290.cnf-k5-r16.6.cnf-0.2-0.1-0.4.cnfP&	0.12\%	\\   \hline
 k5-r21.117-v290.cnf-k5-r16.6.cnf-0.4-0.1-0.1.cnfP&	0.24\%	\\   \hline
 k7-r59.0.cnf-k7-r87.79-v90.cnf-0.2-0.1-0.4.cnfP&	0.21\%	\\   \hline
 k7-r59.0.cnf-k7-r87.79-v90.cnf-0.2-0.2-0.4.cnfP&	0.41\%	\\   \hline
 k7-r59.0.cnf-k7-r87.79-v90.cnf-0.2-0.4-0.2.cnfP&	0.80\%	\\   \hline
 k7-r59.0.cnf-k7-r87.79-v90.cnf-0.4-0.1-0.4.cnfP&	0.04\%	\\   \hline
 k7-r59.0.cnf-k7-r87.79-v90.cnf-0.4-0.2-0.4.cnfP&	0.09\%	\\   \hline
 k7-r59.0.cnf-k7-r87.79-v90.cnf-0.4-0.4-0.2.cnfP&	0.18\%	\\   \hline
 k7-r87.79-v102.cnf-k5-r17.8.cnf-0.8-0.8-0.05.cnfP&	0.00\%	\\   \hline
 k7-r87.79-v106.cnf-k5-r18.0.cnf-0.8-0.8-0.05.cnfP&	0.01\%	\\   \hline
 k7-r87.79-v110.cnf-k5-r18.2.cnf-0.8-0.8-0.05.cnfP&	0.01\%	\\   \hline

\end{tabular}
\end{center}
%\end{minipage}
\end{table} 

\subsection{Experiments}
\subsubsection{Experiment 1: initAssign(F)}
\label{sec:Experiment 1}
Experiment 1 compares three strategies of initialization in our solver. The $biasInit$ suggestion is assign variables based on occurrences of their literals. It assigns True to variables whose positive literal occurs more than its negative literal. Another alternative $randomInit$ is to build a coloring randomly. In a combination of these two variants $randomBiasInit$, the boolean value is assigned to variables based on bias randomly on literals occurrences. the probability to assign True to variable $v_i$ is $\frac{posOccurences[i]}{posOccurences[i]+negOccurences[i]}$. \\
\begin{table}[H]
\label{tab:com}
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|p{1cm}|}
\hline 
    k &$RandomInit$&$BiasInit$&$Bias$-$RandomInit$ \\ \hline
	3&9221.9 (\textbf{55})&9157.76 (54)&\textbf{ 9078.27}(\textbf{55}) \\ \hline
	5&7143.9 (82)&\textbf{4351.09}(\textbf{87})&4582.54 (\textbf{87})\\ \hline

	7& 	6238.51(60)&\textbf{5421.9} (60)& 6310.7(60)\\ \hline
	
\end{tabular}
\end{center}
%\end{minipage}
\end{table} 

\begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K3/e1.pdf}
  \end{center}
  \caption{Three suggestions have very similar performance. In our solver, we use $RanomInit$ for $3SAT$ as initiliazation method because of its simplify.}
  \label{Experiment 1 k3 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K5/e1.pdf}
  \end{center}
  \caption{Two bias suggestions show advantages especially for huge 5SAT instances.}
  \label{Experiment 1 k5 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e1.pdf}
  \end{center}
  \caption{For 7SAT problems, the two random Initialization are similar in performance, while the bias initialization shows its efficiency.}
  \label{Experiment 1 k7 cactus plot}
  \end{figure}
\subsubsection{Experiment 2: pickVar(F)} 
\label{sec:Experiment 2} 
With the comparison of three Variant of $pickVal$ with the one in probSAT, our suggestions are faster and solve more instances in K3 and K5.  For K7,  there are no noticeable differences in results.
\begin{table}[h!]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|p{3cm}|}
\hline 
    k &$probSAT$&$WALK$&$Average$&$Random-Flip$ \\ \hline
	3&9221.9 (55)&7430.12 (57)&\textbf{6161.11}(\textbf{61})&8362.42 (55) \\ \hline
	5&7143.9 (82)&4433.05 (87)&\textbf{3308.16}(\textbf{89})&4052.47(87)\\ \hline

	7& 	6238.51(\textbf{60})& 6358.76(\textbf{60})&6525.597(59)&\textbf{5800.46}(\textbf{60})\\ \hline
	
\end{tabular}
\end{center}
%\end{minipage}
\end{table} 

\begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K3/e2.pdf}
  \end{center}
  \caption{For k3, our suggestions have better performances. The $WALK$ and $Average$ can solve more problems. The best one is the $Average$ (with $\alpha = 1$), which solves $10\%$ more problems.}
  \label{Experiment 2 k3 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K5/e2.pdf}
  \end{center}
  \caption{The improvement through our suggestions are big and stable. They solve more problems efficiently. The $Average$ (with $\alpha = 1$) can solve $8\%$ more problems than the probSAT with only $46\%$ time (in PAR-2 schema). }
  \label{Experiment 2 k5 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e2.pdf}
  \end{center}
  \caption{For $7SAT$ problems, the $WALK$ and $Average$ have generally worse inperformance.The $Random-Flip$ can solve some number of problems as the original $probSAT$ and has shown littel improvement in performance within $125$ Seconds.}
  \label{Experiment 2 k7 cactus plot}
  \end{figure}

\subsubsection{Experiment 3: WALK with Simulated Annealing} 
\label{sec:Experiment 3}
\begin{table}[H]
%begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|p{3cm}|}
\hline 

    k &$WALK$&$WALK-Local$&$WALK-Global$ \\ \hline      
    3 &\textbf{7430.12}(\textbf{57})&	8346.76(56)	&9023.96(56)  \\ \hline
    5&4433.05(87)	&3330.61(89)	&\textbf{3117.45}(\textbf{89}) \\ \hline
    7&6358.76(60)	&\textbf{5409.67}(\textbf{61})&	6566.06(59) \\ \hline	
\end{tabular}
\end{center}
%\end{minipage}
\end{table} 

\begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K3/e3w.pdf}
  \end{center}
  \caption{The combination with simulated Annealing show worse efficiency than the original $WALK$. They solve one less problems. }
  \label{Experiment 3 k3-w cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K5/e3w.pdf}
  \end{center}
  \caption{Two bias suggestions show advantages especially for huge instances.}
  \label{Experiment 3 k5-w cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e3w.pdf}
  \end{center}
  \caption{For 7SAT problems, the two random Initialization are similar in performance, while the bias initialization shows its efficiency.}
  \label{Experiment 3 k7-w cactus plot}
  \end{figure}
\subsubsection{Experiment 4: Average with Simulated Annealing} 
\label{sec:Experiment 4}
\begin{table}[h!]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|p{3cm}|}
\hline 

    k &$Average$&$Average-Local$&$Average-Global$ \\ \hline      
    3 & \textbf{6161.11}(\textbf{61})	&9254.18(53)&	9870.25(53) \\ \hline
    5& 3308.16(89)	&\textbf{2793.32}(89)&	2939.74(89)\\ \hline
    7& 6525.59(59)&\textbf{	3829.95}(\textbf{65})	&5738.2(61)\\ \hline	
\end{tabular}
\end{center}
%\end{minipage}
\end{table} 

  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K3/e3a.pdf}
  \end{center}
  \caption{The performances of these three algorithms are guiet semiliar for small problems within $50$ Seconds. The original Average can solve $15\%$ problems.}
  \label{Experiment 4 k3 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K5/e3a.pdf}
  \end{center}
  \caption{There are not big differences in  $Average$ with different combination of simulated annealing. They have shown small Advantages in  solving huge problems.}
  \label{Experiment 4 k5 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e3a.pdf}
  \end{center}
  \caption{For $7SAT$ problems, the $Local$ version can solve 6  problems more than the original $Average$. It has also shown its efficiency in solving huge $7SAT$ problems.  The $Local$ (with $\alpha = 2$) can solve $10\%$ more problems than the probSAT within less than $60\%$ time (in PAR-2 schema). }
  \label{Experiment 4 k7 cactus plot}
  \end{figure}
\subsubsection{Experiment 5: Random-Flip with Simulated Annealing} 
\label{sec:Experiment 5}
  \begin{table}[H]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|p{3cm}|}
\hline 

    k &$Random-Flip$&$Random-Flip-Local$&$Random-Flip-Global$ \\ \hline      
    3 &  8362.42(55)&8409.8(55)	&\textbf{7308.01}(\textbf{58})\\ \hline
    5&4052.47(87)&	4132.07(87)&\textbf{4003.06}(\textbf{88}) \\ \hline
    7& 5800.46(60) &6792.23(59) &	\textbf{4903.61}(\textbf{60})\\ \hline
	
\end{tabular}
\end{center}
%\end{minipage}
\end{table}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K3/e3r.pdf}
  \end{center}
  \caption{Three suggestions have very similar performance.}
  \label{Experiment 5 k3 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K5/e3r.pdf}
  \end{center}
  \caption{Two bias suggestions show advantages especially for huge instances.}
  \label{Experiment 5 k5 cactus plot} 
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e3r.pdf}
  \end{center}
  \caption{For 7SAT problems, the two random Initialization are similar in performance, while the bias initialization shows its efficiency.}
  \label{Experiment 5 k7 cactus plot}
  \end{figure}
  
\begin{table}[H]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|l|l|p{2cm}|}
\hline 

    k &$Average$&$Average\-Local$&$Average\-Global$ &$RF$& $RF\-Local$& $RF\-Global$ \\ \hline      
    3 &$5.43\%$&$2.43\%$&$5.43\%$&$9.98\%$&$10.01\%$&$3.13\%$\\ \hline
    5& $4.07\%$&$0.35\%$&$0.00\%$&$9.18\%$&$9.17\%$&$0.33\%$\\ \hline
    7&$2.28\%$&$0.03\%$&$0.00\%$&$4.30\%$&$4.14\%$&$0.05\%$\\ \hline
\end{tabular}
\end{center}
%\end{minipage}
\end{table}
  
\subsubsection{Experiment 6: probSAT vs WALK.} 
\label{sec:Experiment 6} 
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e4w.pdf}
  \end{center}
  \caption{Three suggestions have very similar performance.}
  \label{Experiment 6 k3 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K5/e4w.pdf}
  \end{center}
  \caption{Two bias suggestions show advantages especially for huge instances.}
  \label{Experiment 6 k5 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e4w.pdf}
  \end{center}
  \caption{For 7SAT problems, the two random Initialization are similar in performance, while the bias initialization shows its efficiency.}
  \label{Experiment 7 k7 cactus plot}
  \end{figure}

\subsubsection{Experiment 7: probSAT vs Average.}  
\label{sec:Experiment 7} 
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K3/e4a.pdf}
  \end{center}
  \caption{Three suggestions have very similar performance.}
  \label{Experiment 7 k3 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K5/e4a.pdf}
  \end{center}
  \caption{Two bias suggestions show advantages especially for huge instances.}
  \label{Experiment 7 k5 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e4a.pdf}
  \end{center}
  \caption{For 7SAT problems, the two random Initialization are similar in performance, while the bias initialization shows its efficiency.}
  \label{Experiment 7 k7 cactus plot}
  \end{figure}
\subsubsection{Experiment 8:probSAT vs Random-Flip.}  
\label{sec:Experiment 8}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K3/e4r.pdf}
  \end{center}
  \caption{Three suggestions have very similar performance.}
  \label{Experiment 8 k3 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K5/e4r.pdf}
  \end{center}
  \caption{Two bias suggestions show advantages especially for huge instances.}
  \label{Experiment 8 k5 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e4r.pdf}
  \end{center}
  \caption{For 7SAT problems, the two random Initialization are similar in performance, while the bias initialization shows its efficiency.}
  \label{Experiment 8 k7 cactus plot}
  \end{figure} 
\subsubsection{Experiment 9: 2017-UNIF Comparision} 
\label{sec:Experiment 9}
   \begin{table}[H]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|l|p{3cm}|}
\hline 

    k &$probSAT$&$yalSAT$&$WALK$&$Average$/$swpSAT$&$Random-Flip$ \\ \hline      
    3 &9221.9(55)&17062.35(41)&7430.12(57)&\textbf{6161.11}(\textbf{61})&7308.01(58)\\ \hline
    5& 7143.9(82)&5676.63(85)&3330.61(89)&\textbf{2939.74}(\textbf{89})&4003.06(88)\\ \hline
    7& 6238.51(60)&10063.4(54)&5409.67(61)&\textbf{3829.95}(\textbf{65})&4903.61(60)\\ \hline
	
\end{tabular}
\end{center}
%\end{minipage}
\end{table}

   \begin{table}[H]
%\begin{minipage}{\textwidth}                                                                                         
\begin{center}
    \begin{tabular}{|l|l|l|l|l|p{3cm}|}
\hline 

    k &$probSAT$&$WALK$&$Average$/$swpSAT$&$Random-Flip$ \\ \hline      
    3& 954426 &946662 &\textbf{1012761}&988477 \\ \hline
    5& 389453&\textbf{443172}&414765&423364\\ \hline
    7& 248025 &237387 &\textbf{248028}&221107 \\ \hline
	
\end{tabular}
\end{center}
%\end{minipage}
\end{table}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K3/e5.pdf}
  \end{center}
  \caption{Three suggestions have very similar performance.}
  \label{Experiment 9 k3 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K5/e5.pdf}
  \end{center}
  \caption{Two bias suggestions show advantages especially for huge instances.}
  \label{Experiment 9 k5 cactus plot}
  \end{figure}
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/K7/e5.pdf}
  \end{center}
  \caption{For 7SAT problems, the two random Initialization are similar in performance, while the bias initialization shows its efficiency.}
  \label{Experiment 9 k7 cactus plot}
  \end{figure} 
  \begin{figure}[H]
\begin{center}
  \includegraphics[scale = 1]{DATA/UNIF/e5.pdf}
  \end{center}
  \caption{For 7SAT problems, the two random Initialization are similar in performance, while the bias initialization shows its efficiency.}
  \label{Experiment 9 all cactus plot}
  \end{figure} 
\clearpage
\section{Conclusion}
\label{sec:conc}
\subsection{Further work}
\clearpage
\section{Bibliography}
\bibliographystyle{ieeetr}
\bibliography{references}
\end{document}
